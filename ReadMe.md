<!-- # DDoS Attack Detection System

## Overview
A machine learning solution for real-time DDoS attack detection using Random Forest classification. The system processes network flow data to classify traffic as either 'Benign' or 'DDoS' attack.

## Key Features
- Real-time Classification (< 10ms latency)
- High Accuracy (> 95% on test data)
- Comprehensive Logging & Monitoring

## Quick Start

### 1. Setup Environment
```bash
# Clone the repository
git clone https://github.com/Apurva3509/DuneSec.git
cd DuneSec

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

```bash
# Create necessary directories
mkdir -p data/raw
mkdir -p data/processed
mkdir -p data/test
mkdir -p models/preprocessors
mkdir -p reports/figures
mkdir -p logs

# Place your network traffic CSV file in data/raw/network_traffic.csv
```

### 3. Run the Pipeline
```bash
# Step 1: Split the data into train (80%) and test (20%) sets
python main.py --mode split

# Step 2: Train the model
python main.py --mode train

# Step 3: Evaluate the model on test set
python main.py --mode test

# Step 4: Make predictions (when you have new data)
python main.py --mode predict
```


### 4. View Results
- Model artifacts: `models/`
- Performance metrics: `reports/results/`
- Visualizations: `reports/figures/`
- Logs: `logs/app.log`


## Model Performance
- Accuracy: 99.2%
- Precision: 98.7%
- Recall: 99.5%
- F1-Score: 99.1%
- ROC-AUC: 0.998
- Average Prediction Time: 5.3ms

## Monitoring & Logging
- Real-time performance metrics
- Feature importance tracking
- Data drift detection
- Model versioning with MLflow

## Documentation
- [Analysis & Insights](NOTES.md) - Detailed EDA findings and design decisions
- [API Documentation](docs/api.md)
- [Model Architecture](docs/model.md)

## Contributing
1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

# Analysis & Design Notes

## EDA Insights
[Reference to DDoS_detection.ipynb for EDA implementation]

The system will:
- Drop highly correlated features
- Preprocess the data
- Train the XGBoost model
- Generate performance reports
- Save the model and preprocessors

You can find:
- Model performance metrics in reports/figures/
- Trained model in models/model.joblib
- Preprocessors in models/preprocessors/
- Logs in logs/app.log -->

# DDoS Attack Detection System

![Project Banner](src/ddos.png)

## Introduction
In this project, we develop a **machine learning solution** for real-time DDoS attack detection using **Random Forest classification**. The dataset consists of network traffic flows collected using **CICFlowMeterV3**, containing both benign traffic and traffic from **DDoS attacks**. The goal is to **accurately distinguish** between these two classes and deploy an efficient detection system.

---

## Quick Start Guide (aka How to run the code):

#### 1. **Setup Environment**
```bash
# Install Git LFS - if not already installed
brew install git-lfs
git lfs install

# Clone the repository
git clone https://github.com/Apurva3509/DuneSec.git
cd DuneSec-main

# Create virtual environment - OPTIONAL
python -m venv venv
source venv/bin/activate

# Install dependencies - OPTIONAL
pip install -r requirements.txt
```

#### 2. **Directory Structure**
```bash
# Create necessary directories
mkdir -p data/raw
mkdir -p data/processed
mkdir -p data/test
mkdir -p models/preprocessors
mkdir -p reports/figures
mkdir -p logs
```
> **Note:** Place your network traffic CSV file in `data/raw/network_traffic.csv`.

#### 3. **Run the Pipeline**
```bash
# Step 1: Split the data into train (80%) and test (20%) sets
python main.py --mode split

# Step 2: Train the model
python main.py --mode train

# Step 3: Evaluate the model on test set
python main.py --mode test

```
---

## Assignment Breakdown

### Data Exploration & Analysis
Before building the model, an **Exploratory Data Analysis (EDA)** was performed to gain insights into the dataset:
- **Descriptive Statistics**: Understanding the distribution of features.
- **Data Quality Issues**:
  - Presence of missing values and outliers.
  - Identification of highly correlated features for removal.
- **Visualizations**:
  - Class distribution (`DDoS: 56.7%, BENIGN: 43.3%`).
  - Feature importance and correlation heatmaps.

For details, refer to: 
1. [`Preliminary model notebook`](notebooks/DDoS-detection.ipynb).
2. [`EDA Notebook`](notebooks/data_eda-v2.ipynb).
---

### Modeling Strategy
The chosen model for detecting DDoS attacks is **Random Forest**, due to:
- **High interpretability**: Feature importance tracking.
- **Robustness to noisy data**.
- **Fast inference speed** (~5.3ms per prediction).

## Implementation Details

### 1. Data Pipeline
- **Data Ingestion**: 
  - Implemented network flow data collection from csv file
  - Built robust data loading with error handling and validation
  - Automated data quality checks for missing values and anomalies

- **Preprocessing Pipeline**:
  - Feature scaling using StandardScaler
  - Label encoding for target variable
  - Feature selection based on correlation analysis
  - Data split: 80% training, 20% testing (configured in config.yaml)

### 2. Model Development
- **Algorithm Selection**:
  - Evaluated multiple models (Random Forest, XGBoost, Neural Networks)
  - Selected Random Forest for best balance of accuracy and inference speed
  - Implemented 5-fold cross-validation for robust evaluation

- **Hyperparameter Optimization**:
  - Grid search for parameter tuning
  - Optimized for F1-score
  - Parameters tracked using MLflow

### 3. Evaluation System
- **Performance Metrics**:
  - Monitoring of accuracy, precision, recall
  - Confusion matrix analysis
  - ROC curve and AUC calculation

- **Visualization Pipeline**:
  - Automated generation of performance plots
  - Feature importance visualization
  - Prediction distribution analysis

### 4. Production Pipeline
- **Model Serving**:
  - Joblib serialization for model artifacts
  - Preprocessor versioning
  - Batch prediction capability

### 5. API Implementation
- **FastAPI Service**:
  - Real-time prediction endpoint
  - Model artifact management
  - Input validation
  - Error handling
  - Performance monitoring

- **Deployment Options**:
  - Local development server
  - Docker containerization

- **Testing Tools**:
  - Interactive test script
  - Swagger UI documentation
  - Python client implementation

### Using the API

1. **Start the API Server**:
```bash
# Ensure model is trained first
python main.py --mode train

# Start the API
uvicorn src.api.app:app --reload --port 8000
```

2. **Make Predictions (Open a new terminal while keeping the API running)**:
```bash
# Using test script (recommended for testing)
python src/api/test_prediction.py

# Or using curl
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"features": {...}}'
```

3. **View Documentation**:
- Swagger UI: http://localhost:8000/docs
- Detailed API docs: [API Documentation](docs/api.md)



#### Limitations:
- Computationally expensive for large datasets.
- May require **hyperparameter tuning** to avoid overfitting.

---


## **View Results**
- **Model artifacts**: `models/`
- **Performance metrics**: `reports/results/`
- **Visualizations**: `reports/figures/`
- **Logs**: `logs/app.log`

---

## Results & Evaluation

The model's performance was evaluated using key classification metrics:

| Metric       | Score  |
|-------------|--------|
| **Accuracy**  | 99.2%  |
| **Precision** | 98.7%  |
| **Recall**    | 99.5%  |
| **F1-Score**  | 99.1%  |
| **ROC-AUC**   | 0.998  |
| **Avg Prediction Time** | 5.3ms |

#### **Performance Evaluation**
- **Confusion Matrix**
- **ROC-AUC Curve**
- **Feature Importance Analysis**

> **All results and analysis are saved in:** `reports/results/`

---

## Monitoring & Logging
To ensure reliable performance in real-world scenarios, the system includes:
- **Real-time Performance Monitoring** (latency, accuracy)
- **Feature Importance Tracking**
- **Data Drift Detection**
- **Logging** (`logs/app.log`)

---

## Documentation

- ğŸ”— [**Analysis & Insights**](docs/NOTES.md) - **EDA findings and design decisions**
<!-- - ğŸ“¡ [**API Documentation**](docs/api.md) - **Endpoints & usage** -->
- ğŸ“ [**Model Architecture**](docs/model.md) - **Model structure & training pipeline**

---

## Future Improvements
- Implement **XGBoost for better performance**.
- Develop a **real-time API using FastAPI or Flask**.
- Improve **feature engineering using domain knowledge**.

---

_Developed by [Apurva Patel](https://www.patelapurva.com)_

## Project Structure
```
.
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ test.csv
â”‚   â”‚   â””â”€â”€ train.csv
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ data-original.csv
â”‚       â””â”€â”€ network_traffic.csv
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ NOTES.md
â”‚   â””â”€â”€ model.md
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ app.log
â”œâ”€â”€ mlruns/
â”‚   â”œâ”€â”€ 0/
â”‚   â”‚   â”œâ”€â”€ 2e9eff9f94e34abb994c9520cdae5fc0/
â”‚   â”‚   â”‚   â”œâ”€â”€ artifacts/
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ test_accuracy
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ test_roc_auc
â”‚   â”‚   â”‚   â”œâ”€â”€ params/
â”‚   â”‚   â”‚   â”œâ”€â”€ tags/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mlflow.source.git.commit
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mlflow.source.name
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mlflow.source.type
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ mlflow.user
â”‚   â”‚   â”‚   â””â”€â”€ meta.yaml
â”‚   â”‚   â”œâ”€â”€ 3625057b68ce49c9a27ca9b56ffe27ad/
â”‚   â”‚   â”‚   â”œâ”€â”€ artifacts/
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ test_accuracy
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ test_roc_auc
â”‚   â”‚   â”‚   â”œâ”€â”€ params/
â”‚   â”‚   â”‚   â”œâ”€â”€ tags/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mlflow.source.git.commit
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mlflow.source.name
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mlflow.source.type
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ mlflow.user
â”‚   â”‚   â”‚   â””â”€â”€ meta.yaml
â”‚   â”‚   â”œâ”€â”€ 6077e262c3d74f9e8ef2d9c405cbaf95/
â”‚   â”‚   â”‚   â”œâ”€â”€ artifacts/
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ test_accuracy
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ test_roc_auc
â”‚   â”‚   â”‚   â”œâ”€â”€ params/
â”‚   â”‚   â”‚   â”œâ”€â”€ tags/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mlflow.source.git.commit
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mlflow.source.name
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mlflow.source.type
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ mlflow.user
â”‚   â”‚   â”‚   â””â”€â”€ meta.yaml
â”‚   â”‚   â””â”€â”€ meta.yaml
â”‚   â””â”€â”€ 1/
â”‚       â”œâ”€â”€ 081055f970e441f993a39423ed6cf9c3/
â”‚       â”‚   â”œâ”€â”€ artifacts/
â”‚       â”‚   â”œâ”€â”€ metrics/
â”‚       â”‚   â”‚   â”œâ”€â”€ cv_score_mean
â”‚       â”‚   â”‚   â””â”€â”€ cv_score_std
â”‚       â”‚   â”œâ”€â”€ params/
â”‚       â”‚   â”‚   â”œâ”€â”€ eval_metric
â”‚       â”‚   â”‚   â”œâ”€â”€ learning_rate
â”‚       â”‚   â”‚   â”œâ”€â”€ max_depth
â”‚       â”‚   â”‚   â”œâ”€â”€ n_estimators
â”‚       â”‚   â”‚   â””â”€â”€ objective
â”‚       â”‚   â”œâ”€â”€ tags/
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.git.commit
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.name
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.type
â”‚       â”‚   â”‚   â””â”€â”€ mlflow.user
â”‚       â”‚   â””â”€â”€ meta.yaml
â”‚       â”œâ”€â”€ 27e907663df046ed8a200124db985bc6/
â”‚       â”‚   â”œâ”€â”€ artifacts/
â”‚       â”‚   â”œâ”€â”€ metrics/
â”‚       â”‚   â”‚   â”œâ”€â”€ test_accuracy
â”‚       â”‚   â”‚   â””â”€â”€ test_roc_auc
â”‚       â”‚   â”œâ”€â”€ params/
â”‚       â”‚   â”œâ”€â”€ tags/
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.git.commit
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.name
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.type
â”‚       â”‚   â”‚   â””â”€â”€ mlflow.user
â”‚       â”‚   â””â”€â”€ meta.yaml
â”‚       â”œâ”€â”€ 511934cf31b04653a01169ddbd3c5bf1/
â”‚       â”‚   â”œâ”€â”€ artifacts/
â”‚       â”‚   â”œâ”€â”€ metrics/
â”‚       â”‚   â”‚   â”œâ”€â”€ cv_score_mean
â”‚       â”‚   â”‚   â””â”€â”€ cv_score_std
â”‚       â”‚   â”œâ”€â”€ params/
â”‚       â”‚   â”‚   â”œâ”€â”€ eval_metric
â”‚       â”‚   â”‚   â”œâ”€â”€ learning_rate
â”‚       â”‚   â”‚   â”œâ”€â”€ max_depth
â”‚       â”‚   â”‚   â”œâ”€â”€ n_estimators
â”‚       â”‚   â”‚   â””â”€â”€ objective
â”‚       â”‚   â”œâ”€â”€ tags/
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.git.commit
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.name
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.type
â”‚       â”‚   â”‚   â””â”€â”€ mlflow.user
â”‚       â”‚   â””â”€â”€ meta.yaml
â”‚       â”œâ”€â”€ a5b66f52f27446a1b518ab7908032e80/
â”‚       â”‚   â”œâ”€â”€ artifacts/
â”‚       â”‚   â”œâ”€â”€ metrics/
â”‚       â”‚   â”œâ”€â”€ params/
â”‚       â”‚   â”œâ”€â”€ tags/
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.git.commit
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.name
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.type
â”‚       â”‚   â”‚   â””â”€â”€ mlflow.user
â”‚       â”‚   â””â”€â”€ meta.yaml
â”‚       â”œâ”€â”€ f55208b492c34e9cb3bf89795f6d14af/
â”‚       â”‚   â”œâ”€â”€ artifacts/
â”‚       â”‚   â”œâ”€â”€ metrics/
â”‚       â”‚   â”‚   â”œâ”€â”€ cv_score_mean
â”‚       â”‚   â”‚   â””â”€â”€ cv_score_std
â”‚       â”‚   â”œâ”€â”€ params/
â”‚       â”‚   â”‚   â”œâ”€â”€ eval_metric
â”‚       â”‚   â”‚   â”œâ”€â”€ learning_rate
â”‚       â”‚   â”‚   â”œâ”€â”€ max_depth
â”‚       â”‚   â”‚   â”œâ”€â”€ n_estimators
â”‚       â”‚   â”‚   â””â”€â”€ objective
â”‚       â”‚   â”œâ”€â”€ tags/
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.git.commit
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.name
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.type
â”‚       â”‚   â”‚   â””â”€â”€ mlflow.user
â”‚       â”‚   â””â”€â”€ meta.yaml
â”‚       â”œâ”€â”€ fa8e4d6257cc419f911eaa4caa61d2a2/
â”‚       â”‚   â”œâ”€â”€ artifacts/
â”‚       â”‚   â”œâ”€â”€ metrics/
â”‚       â”‚   â”œâ”€â”€ params/
â”‚       â”‚   â”œâ”€â”€ tags/
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.git.commit
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.name
â”‚       â”‚   â”‚   â”œâ”€â”€ mlflow.source.type
â”‚       â”‚   â”‚   â””â”€â”€ mlflow.user
â”‚       â”‚   â””â”€â”€ meta.yaml
â”‚       â””â”€â”€ meta.yaml
â”œâ”€â”€ model_artifacts/
â”‚   â”œâ”€â”€ label_encoder.joblib
â”‚   â”œâ”€â”€ random_forest_model.joblib
â”‚   â””â”€â”€ scaler.joblib
â”œâ”€â”€ model_artifacts_20250224_1356/
â”‚   â”œâ”€â”€ label_encoder.joblib
â”‚   â”œâ”€â”€ model.joblib
â”‚   â””â”€â”€ scaler.joblib
â”œâ”€â”€ models/
â”‚   â””â”€â”€ random_forest_model.joblib
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ DDoS-detection.ipynb
â”‚   â”œâ”€â”€ data_eda-v1.ipynb
â”‚   â”œâ”€â”€ data_eda-v2.ipynb
â”‚   â”œâ”€â”€ final-v1.ipynb
â”‚   â”œâ”€â”€ trial-v1.ipynb
â”‚   â””â”€â”€ wandb-run-v1.ipynb
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/
â”‚   â”‚   â”œâ”€â”€ confusion_matrix_test_20250224_200818.png
â”‚   â”‚   â”œâ”€â”€ confusion_matrix_train_20250224_200802.png
â”‚   â”‚   â”œâ”€â”€ feature_importance_test_20250224_200818.png
â”‚   â”‚   â”œâ”€â”€ feature_importance_train_20250224_200802.png
â”‚   â”‚   â”œâ”€â”€ prediction_dist_test_20250224_200818.png
â”‚   â”‚   â”œâ”€â”€ prediction_dist_train_20250224_200802.png
â”‚   â”‚   â”œâ”€â”€ roc_curve_test_20250224_200818.png
â”‚   â”‚   â”œâ”€â”€ roc_curve_train_20250224_200802.png
â”‚   â”‚   â”œâ”€â”€ threshold_performance_test_20250224_200818.png
â”‚   â”‚   â””â”€â”€ threshold_performance_train_20250224_200802.png
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ test_results_20250224_200818.json
â”‚       â””â”€â”€ train_results_20250224_200802.json
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ generate_tree.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”‚   â””â”€â”€ initial_split.py
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ model_evaluation.py
â”‚   â”‚   â””â”€â”€ test_predictor.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ model_builder.py
â”‚   â”‚   â””â”€â”€ model_trainer.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logger.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ ReadMe.md
â”œâ”€â”€ ai_engineer_assignment.pdf
â”œâ”€â”€ main.py
â””â”€â”€ requirements.txt
```

